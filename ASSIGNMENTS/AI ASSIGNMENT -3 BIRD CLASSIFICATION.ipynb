{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06513b2",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d850c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccabf26",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2a9dab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale = (1./255),horizontal_flip=True,shear_range=0.2,zoom_range=0.2)\n",
    "test_gen = ImageDataGenerator(rescale = (1./255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fc81bfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 16 classes.\n",
      "Found 157 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train=train_gen.flow_from_directory('C:/Users/svneh/Downloads/archive (6)/train_data/train_data',\n",
    "                                    target_size=(120,120),\n",
    "                                    class_mode='categorical',\n",
    "                                    batch_size=8)\n",
    "test=test_gen.flow_from_directory('C:/Users/svneh/Downloads/archive (6)/test_data/test_data',\n",
    "                                  target_size=(120,120),\n",
    "                                    class_mode='categorical',\n",
    "                                    batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b6642",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ac695c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Convolution2D(20,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(45,activation = 'relu'),\n",
    "    Dense(16,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c1d3b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_11 (Conv2D)          (None, 118, 118, 20)      560       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 59, 59, 20)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 69620)             0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 45)                3132945   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 16)                736       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,134,241\n",
      "Trainable params: 3,134,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "301b8603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blasti': 0,\n",
       " 'bonegl': 1,\n",
       " 'brhkyt': 2,\n",
       " 'cbrtsh': 3,\n",
       " 'cmnmyn': 4,\n",
       " 'gretit': 5,\n",
       " 'hilpig': 6,\n",
       " 'himbul': 7,\n",
       " 'himgri': 8,\n",
       " 'hsparo': 9,\n",
       " 'indvul': 10,\n",
       " 'jglowl': 11,\n",
       " 'lbicrw': 12,\n",
       " 'mgprob': 13,\n",
       " 'rebimg': 14,\n",
       " 'wcrsrt': 15}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "46b8d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80bdd13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19/19 [==============================] - 48s 3s/step - loss: 2.3758 - accuracy: 0.2067 - val_loss: 2.6395 - val_accuracy: 0.1656\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 57s 3s/step - loss: 2.3473 - accuracy: 0.2067 - val_loss: 2.6575 - val_accuracy: 0.1720\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 58s 3s/step - loss: 2.3584 - accuracy: 0.2133 - val_loss: 2.6559 - val_accuracy: 0.1720\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 59s 3s/step - loss: 2.3360 - accuracy: 0.2067 - val_loss: 2.6466 - val_accuracy: 0.1783\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 43s 2s/step - loss: 2.3339 - accuracy: 0.2067 - val_loss: 2.6147 - val_accuracy: 0.1783\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3460 - accuracy: 0.2067 - val_loss: 2.7004 - val_accuracy: 0.1401\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3837 - accuracy: 0.2067 - val_loss: 2.6379 - val_accuracy: 0.1847\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3309 - accuracy: 0.1867 - val_loss: 2.6325 - val_accuracy: 0.1975\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.3547 - accuracy: 0.2000 - val_loss: 2.6463 - val_accuracy: 0.1975\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.3676 - accuracy: 0.2333 - val_loss: 2.7562 - val_accuracy: 0.0637\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.3967 - accuracy: 0.2133 - val_loss: 2.6740 - val_accuracy: 0.1911\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.3373 - accuracy: 0.2400 - val_loss: 2.6160 - val_accuracy: 0.1911\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3151 - accuracy: 0.2333 - val_loss: 2.6191 - val_accuracy: 0.1975\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3046 - accuracy: 0.2400 - val_loss: 2.6200 - val_accuracy: 0.1911\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.2957 - accuracy: 0.2267 - val_loss: 2.6326 - val_accuracy: 0.1975\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.2829 - accuracy: 0.2200 - val_loss: 2.6410 - val_accuracy: 0.1975\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.2857 - accuracy: 0.2333 - val_loss: 2.6578 - val_accuracy: 0.1847\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.3080 - accuracy: 0.2400 - val_loss: 2.6059 - val_accuracy: 0.1975\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.3215 - accuracy: 0.2400 - val_loss: 2.7480 - val_accuracy: 0.1592\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.2868 - accuracy: 0.2267 - val_loss: 2.6345 - val_accuracy: 0.1975\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train,epochs =20,\n",
    "                     validation_data = test ,batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d7f161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('birds.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8811dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a44b4aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rebimg', 'wcrsrt', 'jglowl', 'ibicrw', 'mgprob', 'hsparo', 'indvul', 'himgri', 'himbul', 'gretit', 'hilpig', 'cbrtsh', 'cmnmyn', 'bonegl', 'brhkyt', 'blasti']\n"
     ]
    }
   ],
   "source": [
    "output = ['rebimg','wcrsrt','jglowl','ibicrw','mgprob','hsparo',\n",
    "         'indvul','himgri','himbul','gretit','hilpig','cbrtsh',\n",
    "         'cmnmyn','bonegl','brhkyt','blasti']\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "44950d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 112ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img1 = image.load_img(\"C:/Users/svneh/Downloads/jglowl.jpg\",target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "471ccd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img2 = image.load_img(\"C:/Users/svneh/Downloads/ibicrw.jpg\",target_size=(120,120))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2,axis=0)\n",
    "pred = np.argmax(model.predict(img2))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "91dd2b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img3 = image.load_img(\"C:/Users/svneh/Downloads/rebimg.jpg\",target_size=(120,120))\n",
    "img3 = image.img_to_array(img3)\n",
    "img3 = np.expand_dims(img3,axis=0)\n",
    "pred = np.argmax(model.predict(img3))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5cc964fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\svneh\\\\OneDrive\\\\Desktop\\\\py jup'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4ade6239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img4 = image.load_img(\"C:/Users/svneh/Downloads/hilpig.jpg\",target_size=(120,120))\n",
    "img4 = image.img_to_array(img4)\n",
    "img4 = np.expand_dims(img4,axis=0)\n",
    "pred = np.argmax(model.predict(img4))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a8849dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img5 = image.load_img(\"C:/Users/svneh/Downloads/himbul.jpg\",target_size=(120,120))\n",
    "img5 = image.img_to_array(img5)\n",
    "img5 = np.expand_dims(img5,axis=0)\n",
    "pred = np.argmax(model.predict(img5))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4bf04323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img6 = image.load_img(\"C:/Users/svneh/Downloads/hsparo.jpg\",target_size=(120,120))\n",
    "img6 = image.img_to_array(img6)\n",
    "img6 = np.expand_dims(img6,axis=0)\n",
    "pred = np.argmax(model.predict(img6))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c24e342a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img7 = image.load_img(\"C:/Users/svneh/Downloads/indvul.png\",target_size=(120,120))\n",
    "img7 = image.img_to_array(img7)\n",
    "img7 = np.expand_dims(img7,axis=0)\n",
    "pred = np.argmax(model.predict(img7))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "54befda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img8 = image.load_img(\"C:/Users/svneh/Downloads/gretit.png\",target_size=(120,120))\n",
    "img8 = image.img_to_array(img8)\n",
    "img8 = np.expand_dims(img8,axis=0)\n",
    "pred = np.argmax(model.predict(img8))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c02a8ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "4\n",
      "mgprob\n"
     ]
    }
   ],
   "source": [
    "img9 = image.load_img(\"C:/Users/svneh/Downloads/wcrsrt.png\",target_size=(120,120))\n",
    "img9 = image.img_to_array(img9)\n",
    "img9 = np.expand_dims(img9,axis=0)\n",
    "pred = np.argmax(model.predict(img9))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "35843818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img10 = image.load_img(\"C:/Users/svneh/Downloads/mgprop.png\",target_size=(120,120))\n",
    "img10 = image.img_to_array(img10)\n",
    "img10 = np.expand_dims(img10,axis=0)\n",
    "pred = np.argmax(model.predict(img10))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "38d87c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img11 = image.load_img(\"C:/Users/svneh/Downloads/cbrtsh.png\",target_size=(120,120))\n",
    "img11 = image.img_to_array(img11)\n",
    "img11 = np.expand_dims(img11,axis=0)\n",
    "pred = np.argmax(model.predict(img11))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "33866b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img12 = image.load_img(\"C:/Users/svneh/Downloads/cmnmym.png\",target_size=(120,120))\n",
    "img12 = image.img_to_array(img12)\n",
    "img12 = np.expand_dims(img12,axis=0)\n",
    "pred = np.argmax(model.predict(img12))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c5a710d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img13 = image.load_img(\"C:/Users/svneh/Downloads/bonegl.png\",target_size=(120,120))\n",
    "img13 = image.img_to_array(img13)\n",
    "img13 = np.expand_dims(img13,axis=0)\n",
    "pred = np.argmax(model.predict(img13))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf35e648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img14 = image.load_img(\"C:/Users/svneh/Downloads/blasti.png\",target_size=(120,120))\n",
    "img14 = image.img_to_array(img14)\n",
    "img14 = np.expand_dims(img14,axis=0)\n",
    "pred = np.argmax(model.predict(img14))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3d72e6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "14\n",
      "brhkyt\n"
     ]
    }
   ],
   "source": [
    "img15 = image.load_img(\"C:/Users/svneh/Downloads/brhkyt.png\",target_size=(120,120))\n",
    "img15 = image.img_to_array(img15)\n",
    "img15 = np.expand_dims(img15,axis=0)\n",
    "pred = np.argmax(model.predict(img15))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3a1c11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hence we can see that the model is not predicting the birds properly hence we can try it with model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394705b",
   "metadata": {},
   "source": [
    "# Model Tuning ( Adding Feature extraction layrrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "62d1f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Convolution2D(15,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Convolution2D(30,(3,3),activation = 'relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Convolution2D(45,(3,3),activation = 'relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Convolution2D(60,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Convolution2D(75,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(62,activation = 'relu'),\n",
    "    Dense(32,activation = 'relu'),\n",
    "    Dense(16,activation = 'relu'),\n",
    "    Dense(16,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "11f8166e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 118, 118, 15)      420       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 59, 59, 15)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 57, 57, 30)        4080      \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 28, 28, 30)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 26, 26, 45)        12195     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 13, 13, 45)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 11, 11, 60)        24360     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 5, 5, 60)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 3, 3, 75)          40575     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 1, 1, 75)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 75)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 62)                4712      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 32)                2016      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,158\n",
      "Trainable params: 89,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b9e7e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ccc66d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/19 [==============================] - 30s 2s/step - loss: 2.7775 - accuracy: 0.0667 - val_loss: 2.7618 - val_accuracy: 0.1019\n",
      "Epoch 2/50\n",
      "19/19 [==============================] - 26s 1s/step - loss: 2.7586 - accuracy: 0.1333 - val_loss: 2.7459 - val_accuracy: 0.1274\n",
      "Epoch 3/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.7415 - accuracy: 0.1333 - val_loss: 2.7358 - val_accuracy: 0.1274\n",
      "Epoch 4/50\n",
      "19/19 [==============================] - 30s 2s/step - loss: 2.7080 - accuracy: 0.1133 - val_loss: 2.7433 - val_accuracy: 0.1210\n",
      "Epoch 5/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.7382 - accuracy: 0.0933 - val_loss: 2.7142 - val_accuracy: 0.1210\n",
      "Epoch 6/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.7203 - accuracy: 0.1000 - val_loss: 2.7053 - val_accuracy: 0.1210\n",
      "Epoch 7/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.6569 - accuracy: 0.1467 - val_loss: 2.7435 - val_accuracy: 0.1274\n",
      "Epoch 8/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.6798 - accuracy: 0.1267 - val_loss: 2.7217 - val_accuracy: 0.1529\n",
      "Epoch 9/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.6299 - accuracy: 0.1733 - val_loss: 2.7022 - val_accuracy: 0.1210\n",
      "Epoch 10/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.6289 - accuracy: 0.1533 - val_loss: 2.7127 - val_accuracy: 0.1274\n",
      "Epoch 11/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.6133 - accuracy: 0.1467 - val_loss: 2.7072 - val_accuracy: 0.1083\n",
      "Epoch 12/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.5985 - accuracy: 0.1133 - val_loss: 2.7118 - val_accuracy: 0.1274\n",
      "Epoch 13/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.5526 - accuracy: 0.1467 - val_loss: 2.7245 - val_accuracy: 0.0701\n",
      "Epoch 14/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.5490 - accuracy: 0.1733 - val_loss: 2.7029 - val_accuracy: 0.1210\n",
      "Epoch 15/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.5671 - accuracy: 0.1933 - val_loss: 2.7024 - val_accuracy: 0.1210\n",
      "Epoch 16/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.5911 - accuracy: 0.1933 - val_loss: 2.7003 - val_accuracy: 0.1274\n",
      "Epoch 17/50\n",
      "19/19 [==============================] - 29s 2s/step - loss: 2.5278 - accuracy: 0.2000 - val_loss: 2.6979 - val_accuracy: 0.1210\n",
      "Epoch 18/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.4749 - accuracy: 0.2000 - val_loss: 2.7054 - val_accuracy: 0.1210\n",
      "Epoch 19/50\n",
      "19/19 [==============================] - 27s 2s/step - loss: 2.4886 - accuracy: 0.2067 - val_loss: 2.6790 - val_accuracy: 0.1146\n",
      "Epoch 20/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.4661 - accuracy: 0.2067 - val_loss: 2.6627 - val_accuracy: 0.1083\n",
      "Epoch 21/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 2.4687 - accuracy: 0.1933 - val_loss: 2.6742 - val_accuracy: 0.1656\n",
      "Epoch 22/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 2.4557 - accuracy: 0.1800 - val_loss: 2.8396 - val_accuracy: 0.1210\n",
      "Epoch 23/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.4292 - accuracy: 0.1533 - val_loss: 2.6755 - val_accuracy: 0.1338\n",
      "Epoch 24/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.3272 - accuracy: 0.2133 - val_loss: 2.7259 - val_accuracy: 0.1720\n",
      "Epoch 25/50\n",
      "19/19 [==============================] - 31s 2s/step - loss: 2.2773 - accuracy: 0.2200 - val_loss: 2.7094 - val_accuracy: 0.1656\n",
      "Epoch 26/50\n",
      "19/19 [==============================] - 30s 2s/step - loss: 2.2039 - accuracy: 0.2533 - val_loss: 2.7034 - val_accuracy: 0.1656\n",
      "Epoch 27/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 2.1453 - accuracy: 0.2600 - val_loss: 2.7774 - val_accuracy: 0.1465\n",
      "Epoch 28/50\n",
      "19/19 [==============================] - 30s 2s/step - loss: 2.1559 - accuracy: 0.2733 - val_loss: 2.7124 - val_accuracy: 0.1720\n",
      "Epoch 29/50\n",
      "19/19 [==============================] - 31s 2s/step - loss: 2.0974 - accuracy: 0.2933 - val_loss: 2.8033 - val_accuracy: 0.1465\n",
      "Epoch 30/50\n",
      "19/19 [==============================] - 31s 2s/step - loss: 2.0359 - accuracy: 0.2400 - val_loss: 2.7384 - val_accuracy: 0.1274\n",
      "Epoch 31/50\n",
      "19/19 [==============================] - 31s 2s/step - loss: 1.9586 - accuracy: 0.2933 - val_loss: 2.9330 - val_accuracy: 0.2166\n",
      "Epoch 32/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.9898 - accuracy: 0.3267 - val_loss: 2.8359 - val_accuracy: 0.1019\n",
      "Epoch 33/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.9849 - accuracy: 0.2667 - val_loss: 2.9023 - val_accuracy: 0.1656\n",
      "Epoch 34/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.8850 - accuracy: 0.2867 - val_loss: 3.1135 - val_accuracy: 0.1592\n",
      "Epoch 35/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 1.9481 - accuracy: 0.3333 - val_loss: 2.8762 - val_accuracy: 0.1529\n",
      "Epoch 36/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.7834 - accuracy: 0.3533 - val_loss: 3.0608 - val_accuracy: 0.1975\n",
      "Epoch 37/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.8118 - accuracy: 0.4000 - val_loss: 3.2737 - val_accuracy: 0.1465\n",
      "Epoch 38/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.8708 - accuracy: 0.3000 - val_loss: 2.9573 - val_accuracy: 0.1847\n",
      "Epoch 39/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.7042 - accuracy: 0.4067 - val_loss: 3.3099 - val_accuracy: 0.1720\n",
      "Epoch 40/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.7063 - accuracy: 0.4067 - val_loss: 3.4032 - val_accuracy: 0.1338\n",
      "Epoch 41/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.7592 - accuracy: 0.4000 - val_loss: 3.3134 - val_accuracy: 0.2038\n",
      "Epoch 42/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.6813 - accuracy: 0.4200 - val_loss: 3.3371 - val_accuracy: 0.1529\n",
      "Epoch 43/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 1.5221 - accuracy: 0.4600 - val_loss: 3.5573 - val_accuracy: 0.1592\n",
      "Epoch 44/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.5011 - accuracy: 0.4733 - val_loss: 3.7309 - val_accuracy: 0.1783\n",
      "Epoch 45/50\n",
      "19/19 [==============================] - 28s 2s/step - loss: 1.4673 - accuracy: 0.4600 - val_loss: 3.5507 - val_accuracy: 0.1847\n",
      "Epoch 46/50\n",
      "19/19 [==============================] - 29s 2s/step - loss: 1.4187 - accuracy: 0.4533 - val_loss: 3.8640 - val_accuracy: 0.1592\n",
      "Epoch 47/50\n",
      "19/19 [==============================] - 28s 1s/step - loss: 1.4263 - accuracy: 0.4867 - val_loss: 3.9452 - val_accuracy: 0.1338\n",
      "Epoch 48/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.2814 - accuracy: 0.5133 - val_loss: 4.5782 - val_accuracy: 0.1911\n",
      "Epoch 49/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.3525 - accuracy: 0.5000 - val_loss: 4.0549 - val_accuracy: 0.1975\n",
      "Epoch 50/50\n",
      "19/19 [==============================] - 27s 1s/step - loss: 1.2944 - accuracy: 0.5067 - val_loss: 4.3617 - val_accuracy: 0.1529\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train,epochs =50,\n",
    "                     validation_data = test ,\n",
    "                      batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a52f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = image.load_img(\"C:/Users/svneh/Downloads/jglowl.jpg\",target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = image.load_img(\"C:/Users/svneh/Downloads/ibicrw.jpg\",target_size=(120,120))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2,axis=0)\n",
    "pred = np.argmax(model.predict(img2))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9531a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = image.load_img(\"C:/Users/svneh/Downloads/rebimg.jpg\",target_size=(120,120))\n",
    "img3 = image.img_to_array(img3)\n",
    "img3 = np.expand_dims(img3,axis=0)\n",
    "pred = np.argmax(model.predict(img3))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f862dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img6 = image.load_img(\"C:/Users/svneh/Downloads/hsparo.jpg\",target_size=(120,120))\n",
    "img6 = image.img_to_array(img6)\n",
    "img6 = np.expand_dims(img6,axis=0)\n",
    "pred = np.argmax(model.predict(img6))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "img5 = image.load_img(\"C:/Users/svneh/Downloads/himbul.jpg\",target_size=(120,120))\n",
    "img5 = image.img_to_array(img5)\n",
    "img5 = np.expand_dims(img5,axis=0)\n",
    "pred = np.argmax(model.predict(img5))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab1392",
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = image.load_img(\"C:/Users/svneh/Downloads/hilpig.jpg\",target_size=(120,120))\n",
    "img4 = image.img_to_array(img4)\n",
    "img4 = np.expand_dims(img4,axis=0)\n",
    "pred = np.argmax(model.predict(img4))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "img7 = image.load_img(\"C:/Users/svneh/Downloads/indvul.png\",target_size=(120,120))\n",
    "img7 = image.img_to_array(img7)\n",
    "img7 = np.expand_dims(img7,axis=0)\n",
    "pred = np.argmax(model.predict(img7))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81681216",
   "metadata": {},
   "outputs": [],
   "source": [
    "img8 = image.load_img(\"C:/Users/svneh/Downloads/gretit.png\",target_size=(120,120))\n",
    "img8 = image.img_to_array(img8)\n",
    "img8 = np.expand_dims(img8,axis=0)\n",
    "pred = np.argmax(model.predict(img8))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf05ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img9 = image.load_img(\"C:/Users/svneh/Downloads/wcrsrt.png\",target_size=(120,120))\n",
    "img9 = image.img_to_array(img9)\n",
    "img9 = np.expand_dims(img9,axis=0)\n",
    "pred = np.argmax(model.predict(img9))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img10 = image.load_img(\"C:/Users/svneh/Downloads/mgprop.png\",target_size=(120,120))\n",
    "img10 = image.img_to_array(img10)\n",
    "img10 = np.expand_dims(img10,axis=0)\n",
    "pred = np.argmax(model.predict(img10))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img11 = image.load_img(\"C:/Users/svneh/Downloads/cbrtsh.png\",target_size=(120,120))\n",
    "img11 = image.img_to_array(img11)\n",
    "img11 = np.expand_dims(img11,axis=0)\n",
    "pred = np.argmax(model.predict(img11))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb082b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img12 = image.load_img(\"C:/Users/svneh/Downloads/cmnmym.png\",target_size=(120,120))\n",
    "img12 = image.img_to_array(img12)\n",
    "img12 = np.expand_dims(img12,axis=0)\n",
    "pred = np.argmax(model.predict(img12))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43411f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "img13 = image.load_img(\"C:/Users/svneh/Downloadsbonegl.png\",target_size=(120,120))\n",
    "img13 = image.img_to_array(img13)\n",
    "img13 = np.expand_dims(img13,axis=0)\n",
    "pred = np.argmax(model.predict(img13))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5409c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "img14 = image.load_img(\"C:/Users/svneh/Downloads/blasti.png\",target_size=(120,120))\n",
    "img14 = image.img_to_array(img14)\n",
    "img14 = np.expand_dims(img14,axis=0)\n",
    "pred = np.argmax(model.predict(img14))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "img15 = image.load_img(\"C:/Users/svneh/Downloads/brhkyt.png\",target_size=(120,120))\n",
    "img15 = image.img_to_array(img15)\n",
    "img15 = np.expand_dims(img15,axis=0)\n",
    "pred = np.argmax(model.predict(img15))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e41f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hence we can see that it is still not predicting properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e515e36",
   "metadata": {},
   "source": [
    "# Model Tuning(with Drop out , batch normalisation , early stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Convolution2D(12,(3,3),activation = 'relu',input_shape=(120,120,3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.2),\n",
    "    Convolution2D(24,(3,3),activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.2),\n",
    "    Convolution2D(36,(3,3),activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(2,2),\n",
    "    Dropout(0.2),\n",
    "    Flatten(),\n",
    "    Dense(62,activation = 'relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    Dense(32,activation = 'relu'),\n",
    "    Dense(16,activation = 'relu'),\n",
    "    Dense(16,activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cc3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90295ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',metrics=['accuracy'],loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0eb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor = 'val_accuracy',patience = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994dbbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit = model.fit(train,epochs =50,\n",
    "                     validation_data = test ,\n",
    "                      batch_size=5,\n",
    "                      callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb36c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "img7 = image.load_img(\"C:/Users/svneh/Downloads/indvul.png\",target_size=(120,120))\n",
    "img7 = image.img_to_array(img7)\n",
    "img7 = np.expand_dims(img7,axis=0)\n",
    "pred = np.argmax(model.predict(img7))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b43813",
   "metadata": {},
   "outputs": [],
   "source": [
    "img4 = image.load_img(\"C:/Users/svneh/Downloads/hilpig.jpg\",target_size=(120,120))\n",
    "img4 = image.img_to_array(img4)\n",
    "img4 = np.expand_dims(img4,axis=0)\n",
    "pred = np.argmax(model.predict(img4))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09355716",
   "metadata": {},
   "outputs": [],
   "source": [
    "img5 = image.load_img(\"C:/Users/svneh/Downloads/himbul.jpg\",target_size=(120,120))\n",
    "img5 = image.img_to_array(img5)\n",
    "img5 = np.expand_dims(img5,axis=0)\n",
    "pred = np.argmax(model.predict(img5))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e6aabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img6 = image.load_img(\"C:/Users/svneh/Downloads/hsparo.jpg\",target_size=(120,120))\n",
    "img6 = image.img_to_array(img6)\n",
    "img6 = np.expand_dims(img6,axis=0)\n",
    "pred = np.argmax(model.predict(img6))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49833bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = image.load_img(\"C:/Users/svneh/Downloads/rebimg.jpg\",target_size=(120,120))\n",
    "img3 = image.img_to_array(img3)\n",
    "img3 = np.expand_dims(img3,axis=0)\n",
    "pred = np.argmax(model.predict(img3))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebe508",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = image.load_img(\"C:/Users/svneh/Downloads/ibicrw.jpg\",target_size=(120,120))\n",
    "img2 = image.img_to_array(img2)\n",
    "img2 = np.expand_dims(img2,axis=0)\n",
    "pred = np.argmax(model.predict(img2))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = image.load_img(\"C:/Users/svneh/Downloads/jglowl.jpg\",target_size=(120,120))\n",
    "img1 = image.img_to_array(img1)\n",
    "img1 = np.expand_dims(img1,axis=0)\n",
    "pred = np.argmax(model.predict(img1))\n",
    "print(pred)\n",
    "print(output[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4df1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d1dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
